import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import re
import os
import unicodedata
import argparse
import random
import threading
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from requests.adapters import HTTPAdapter
from urllib3.util import Retry

# ==========================================
# âš™ï¸ è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
# ä¸¦åˆ—æ•°ã‚’20ã«å¤‰æ›´
MAX_WORKERS = 20
MAX_RETRIES = 5
RETRY_DELAY = 3
TIMEOUT_SEC = 20

UA_LIST = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
]

print_lock = threading.Lock()


def safe_print(msg):
    with print_lock:
        timestamp = time.strftime("%H:%M:%S")
        print(f"[{timestamp}] {msg}", flush=True)


def clean_text(text):
    if not text:
        return ""
    text = unicodedata.normalize("NFKC", str(text))
    return (
        text.replace("\n", "")
        .replace("\r", "")
        .replace("Â¥", "")
        .replace(",", "")
        .strip()
    )


def get_column_names():
    """CSVã®ã‚«ãƒ©ãƒ å®šç¾©ã‚’ä¸€ç®‡æ‰€ã§ç®¡ç†"""
    cols = [
        "date",
        "jcd",
        "rno",
        "wind",
        "res1",
        "rank1",
        "rank2",
        "rank3",
        "tansho",
        "nirentan",
        "sanrentan",
        "sanrenpuku",
        "payout",
    ]
    for i in range(1, 7):
        # pid (é¸æ‰‹ID) ã‚’è¿½åŠ 
        cols.extend([f"pid{i}", f"wr{i}", f"mo{i}", f"ex{i}", f"f{i}", f"st{i}"])
    return cols


def get_session():
    session = requests.Session()
    retries = Retry(
        total=MAX_RETRIES,
        backoff_factor=1,
        status_forcelist=[500, 502, 503, 504],
        allowed_methods=["GET"],
    )
    # ä¸¦åˆ—æ•°ã«åˆã‚ã›ã¦ãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚ºã‚‚æ‹¡å¼µ
    adapter = HTTPAdapter(
        pool_connections=MAX_WORKERS, pool_maxsize=MAX_WORKERS, max_retries=retries
    )
    session.mount("https://", adapter)
    return session


def get_soup(session, url):
    for i in range(MAX_RETRIES):
        try:
            headers = {"User-Agent": random.choice(UA_LIST)}
            res = session.get(url, headers=headers, timeout=TIMEOUT_SEC)
            res.encoding = res.apparent_encoding

            if res.status_code == 200:
                if "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“" in res.text or "ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹" in res.text:
                    return None, "SKIP"
                return BeautifulSoup(res.text, "html.parser"), None

            if res.status_code == 404:
                return None, "ERROR"

            time.sleep(random.uniform(1, 2))
        except Exception:
            time.sleep(RETRY_DELAY)

    return None, "ERROR"


def extract_payout(soup, key_text):
    if not soup:
        return 0
    try:
        # table.is-w495 ã‚’ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆã§ç‹™ã†
        for tbl in soup.select("table.is-w495"):
            if key_text in tbl.text:
                rows = tbl.select("tr")
                for tr in rows:
                    if key_text in tr.text:
                        # é‡‘é¡ã¯è¡Œã®å¾Œã‚ã®æ–¹ã«ã‚ã‚‹ã€‚
                        # äººæ°—é †(1æ¡~2æ¡)ã‚’æ‹¾ã‚ãªã„ã‚ˆã†ã€å¾Œã‚ã‹ã‚‰èµ°æŸ»ã—ã¦ã€Œ100ä»¥ä¸Šã€ã®æ•°å€¤ã‚’æ¢ã™
                        tds = tr.select("td")
                        if not tds:
                            continue

                        for td in reversed(tds):
                            txt = clean_text(td.text)
                            if txt.isdigit():
                                val = int(txt)
                                # 100å††ä»¥ä¸Šãªã‚‰é‡‘é¡ã¨ã¿ãªã™ï¼ˆäººæ°—é †ãªã©ã®èª¤å–å¾—é˜²æ­¢ï¼‰
                                if val >= 100:
                                    return val
    except:
        pass
    return 0


def scrape_race_data(session, jcd, rno, date_str):
    base_url = "https://www.boatrace.jp/owpc/pc/race"

    url_res = f"{base_url}/raceresult?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    url_bef = f"{base_url}/beforeinfo?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    url_lst = f"{base_url}/racelist?rno={rno}&jcd={jcd:02d}&hd={date_str}"

    soup_res, err = get_soup(session, url_res)
    if err == "SKIP" or not soup_res:
        return None

    soup_before, _ = get_soup(session, url_bef)
    soup_list, _ = get_soup(session, url_lst)

    try:
        row = {"date": date_str, "jcd": jcd, "rno": rno}

        # å¤©å€™ãƒ»é¢¨ (beforeinfoã‹ã‚‰å–å¾—)
        row["wind"] = 0.0
        if soup_before:
            try:
                # ã‚¯ãƒ©ã‚¹å "is-windDirection" (é¢¨å‘ãƒ»é¢¨é€Ÿã‚¨ãƒªã‚¢) ã‚’ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆã§å–å¾—
                # â€»ä»¥å‰ã®ã‚³ãƒ¼ãƒ‰ã§ã¯ "is-temperature" (æ°—æ¸©) ã‚’æ‹¾ã£ã¦ã„ã¾ã—ãŸ
                wind_unit = soup_before.select_one(".is-windDirection")
                if wind_unit:
                    wind_data = wind_unit.select_one(".weather1_bodyUnitLabelData")
                    if wind_data:
                        w_txt = clean_text(wind_data.text)
                        m = re.search(r"(\d+)", w_txt)
                        row["wind"] = float(m.group(1)) if m else 0.0
            except:
                pass

        # é †ä½
        row["rank1"], row["rank2"], row["rank3"] = None, None, None
        try:
            result_rows = soup_res.select("table.is-w495 tbody tr")
            for idx, r_key in enumerate(["rank1", "rank2", "rank3"]):
                if len(result_rows) > idx:
                    # ç€é †ã®æ•°å­—ã‚’å–å¾—
                    rank_td = result_rows[idx].select("td")
                    if len(rank_td) >= 2:
                        r_txt = clean_text(rank_td[1].text)
                        if r_txt.isdigit():
                            row[r_key] = int(r_txt)
        except:
            pass

        row["res1"] = 1 if row.get("rank1") == 1 else 0

        # æ‰•ã„æˆ»ã—
        row["tansho"] = extract_payout(soup_res, "å˜å‹")
        row["nirentan"] = extract_payout(soup_res, "2é€£å˜")
        row["sanrentan"] = extract_payout(soup_res, "3é€£å˜")
        row["sanrenpuku"] = extract_payout(soup_res, "3é€£è¤‡")
        row["payout"] = row["sanrentan"]

        # å„è‰‡ãƒ‡ãƒ¼ã‚¿å–å¾—
        for i in range(1, 7):
            # åˆæœŸåŒ–
            row[f"pid{i}"] = 0  # é¸æ‰‹ID
            row[f"wr{i}"] = 0.0  # å‹ç‡
            row[f"mo{i}"] = 0.0  # ãƒ¢ãƒ¼ã‚¿ãƒ¼
            row[f"ex{i}"] = 0.0  # å±•ç¤ºã‚¿ã‚¤ãƒ 
            row[f"f{i}"] = 0  # ãƒ•ãƒ©ã‚¤ãƒ³ã‚°
            row[f"st{i}"] = 0.20  # å¹³å‡ST

            # 1. å‡ºèµ°è¡¨(racelist)ã‹ã‚‰ ID, å‹ç‡, å¹³å‡ST, Fæ•° ã‚’å–å¾—
            if soup_list:
                try:
                    # æ ç•ªã”ã¨ã®tbodyã‚’å–å¾— (is-fs12ã‚¯ãƒ©ã‚¹ã‚’æŒã¤tbody)
                    tbodies = soup_list.select("tbody.is-fs12")
                    if len(tbodies) >= i:
                        tbody = tbodies[i - 1]  # æ ç•ªã«å¯¾å¿œã™ã‚‹tbody

                        # --- é¸æ‰‹ID (ç™»ç•ª) ---
                        # ã‚¯ãƒ©ã‚¹å(is-fs11)ã«ä¾å­˜ã›ãšã€ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‹ã‚‰ã€Œ4æ¡ã®æ•°å­—ã€ã‚’æ¢ã™
                        # ç™»éŒ²ç•ªå·ã¯é€šå¸¸2000ç•ªå°ï½5000ç•ªå°ã€‚å¹´é½¢(2æ¡)ã‚„ä½“é‡(3æ¡)ã¨åŒºåˆ¥å¯èƒ½ã€‚
                        txt_all = clean_text(tbody.text)
                        # å…ˆé ­ã‹ã‚‰æ¤œç´¢ã—ã¦æœ€åˆã«è¦‹ã¤ã‹ã‚‹4æ¡ã®æ•°å­—(ç™»éŒ²ç•ªå·)ã‚’å–å¾—
                        pid_match = re.search(r"([2-5]\d{3})", txt_all)
                        if pid_match:
                            row[f"pid{i}"] = int(pid_match.group(1))

                        # --- å‹ç‡, ãƒ¢ãƒ¼ã‚¿ãƒ¼, å¹³å‡ST, F ---
                        tds = tbody.select("td")
                        full_row_text = " ".join([clean_text(td.text) for td in tds])

                        # å‹ç‡: tdã‚’å€‹åˆ¥ã«ãƒã‚§ãƒƒã‚¯ã—ã¦ç¢ºå®Ÿã«æ‹¾ã†
                        for td in tds:
                            txt = clean_text(td.text)
                            # å®Œå…¨ä¸€è‡´ã ã¨ä½™è¨ˆãªæ–‡å­—ãŒã‚ã‚‹å ´åˆã«å¤±æ•—ã™ã‚‹ãŸã‚ã€éƒ¨åˆ†ä¸€è‡´(search)ã«å¤‰æ›´
                            m = re.search(r"(\d\.\d{2})", txt)
                            if m:
                                val = float(m.group(1))
                                # å‹ç‡ã¯ 1.00 ï½ 9.99 ã®ç¯„å›²ï¼ˆãƒ¢ãƒ¼ã‚¿ãƒ¼2é€£å¯¾ç‡ã¯10.0ä»¥ä¸Šãªã®ã§åŒºåˆ¥å¯èƒ½ï¼‰
                                if 1.0 <= val <= 9.99:
                                    row[f"wr{i}"] = val
                                    break  # æœ€åˆã«è¦‹ã¤ã‹ã‚‹ã®ãŒå…¨å›½å‹ç‡

                        # ãƒ¢ãƒ¼ã‚¿ãƒ¼: XX.XX å½¢å¼ã‚’æ¢ã™
                        mo_matches = re.findall(r"(\d{2}\.\d{2})", full_row_text)
                        if mo_matches:
                            for m_val in mo_matches:
                                if 10.0 <= float(m_val) <= 99.9:
                                    row[f"mo{i}"] = float(m_val)
                                    break

                        # å¹³å‡ST (0.XX)
                        st_match = re.search(r"(0\.\d{2})", full_row_text)
                        if st_match:
                            row[f"st{i}"] = float(st_match.group(1))

                        # Fæ•° (F1, F2...)
                        f_match = re.search(r"F(\d+)", full_row_text)
                        if f_match:
                            row[f"f{i}"] = int(f_match.group(1))

                except:
                    pass

            # 2. ç›´å‰æƒ…å ±(beforeinfo)ã‹ã‚‰ å±•ç¤ºã‚¿ã‚¤ãƒ  ã‚’å–å¾—
            if soup_before:
                try:
                    # is-boatColor1 ~ 6 ã®ã‚¯ãƒ©ã‚¹ã‚’æŒã¤tdã‚’æ¢ã™
                    boat_td = soup_before.select_one(f"td.is-boatColor{i}")
                    if boat_td:
                        # ãã®è¡Œ(tr)ã‚’å–å¾—
                        tr = boat_td.find_parent("tr")
                        if tr:
                            tds = tr.select("td")
                            # å±•ç¤ºã‚¿ã‚¤ãƒ ã¯é€šå¸¸å¾Œã‚ã®æ–¹ã«ã‚ã‚‹ (td[4]ä»¥é™)
                            # å€¤ãŒ "6.XX" ã®ã‚ˆã†ãªå½¢å¼ã‚’æ¢ã™
                            for td in tds[4:]:
                                val = clean_text(td.text)
                                if re.match(r"^\d\.\d{2}$", val):
                                    # 6.50 ~ 7.00 ãã‚‰ã„ã®å€¤ãŒå±•ç¤ºã‚¿ã‚¤ãƒ 
                                    if 6.0 <= float(val) <= 7.5:
                                        row[f"ex{i}"] = float(val)
                                        break
                except:
                    pass

        return row
    except:
        return None


def process_wrapper(args):
    session, jcd, rno, date_str = args
    time.sleep(random.uniform(0.1, 0.4))
    try:
        result = scrape_race_data(session, jcd, rno, date_str)
        if result is None:
            # å¤±æ•—æ™‚ã¯ãƒ­ã‚°ã«æ®‹ã™
            safe_print(
                f"âš ï¸ [SKIP] {date_str} å ´:{jcd:02} R:{rno:02} -> ãƒ‡ãƒ¼ã‚¿ãªã—/å–å¾—å¤±æ•—"
            )
        return result
    except Exception as e:
        safe_print(f"âŒ [ERROR] {date_str} å ´:{jcd:02} R:{rno:02} -> {e}")
        return None


def show_progress(processed, total):
    bar_len = 30
    filled = int(bar_len * processed / total)
    bar = "=" * filled + "-" * (bar_len - filled)
    percent = 100 * processed / total
    print(f"\râ³ [{bar}] {percent:.1f}% ({processed}/{total})", end="")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    today = datetime.now().strftime("%Y-%m-%d")

    parser.add_argument("--start", help="é–‹å§‹æ—¥ (YYYY-MM-DD)")
    parser.add_argument("--end", help="çµ‚äº†æ—¥ (YYYY-MM-DD)")
    parser.add_argument("--year", type=int, help="æŒ‡å®šã—ãŸå¹´å…¨ä½“ã‚’åé›†")

    args = parser.parse_args()

    if args.year:
        start_d = datetime(args.year, 1, 1)
        end_d = datetime(args.year, 12, 31)
    else:
        # ã€ä¿®æ­£ã€‘å¼•æ•°ãŒãªã„å ´åˆã¯ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹éå»ã®æ—¥ä»˜ï¼ˆ2024-12-01ï¼‰ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ã™ã‚‹
        default_date = "2024-12-01"
        s_str = args.start if args.start else default_date
        e_str = args.end if args.end else default_date
        try:
            start_d = datetime.strptime(s_str, "%Y-%m-%d")
            end_d = datetime.strptime(e_str, "%Y-%m-%d")
        except ValueError:
            print("âŒ æ—¥ä»˜ã‚¨ãƒ©ãƒ¼: YYYY-MM-DD å½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            sys.exit(1)

    if start_d > end_d:
        print("âŒ ã‚¨ãƒ©ãƒ¼: é–‹å§‹æ—¥ãŒçµ‚äº†æ—¥ã‚ˆã‚Šå¾Œã«ãªã£ã¦ã„ã¾ã™ã€‚")
        sys.exit(1)

    session = get_session()
    current = start_d

    safe_print(
        f"ğŸš€ åé›†é–‹å§‹: {start_d.strftime('%Y-%m-%d')} ã€œ {end_d.strftime('%Y-%m-%d')}"
    )
    safe_print(f"âš¡ ä¸¦åˆ—ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {MAX_WORKERS}")

    os.makedirs("data", exist_ok=True)
    filename = (
        f"data/race_data_{start_d.strftime('%Y%m%d')}_{end_d.strftime('%Y%m%d')}.csv"
    )

    csv_columns = get_column_names()

    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½œæˆ
    if not os.path.exists(filename):
        pd.DataFrame(columns=csv_columns).to_csv(filename, index=False)

    total_races = 0

    while current <= end_d:
        d_str = current.strftime("%Y%m%d")
        safe_print(f"ğŸ“… {current.strftime('%Y-%m-%d')} ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...")

        tasks = []
        for jcd in range(1, 25):
            for rno in range(1, 13):
                tasks.append((session, jcd, rno, d_str))

        # ã€æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰ã€‘å…¨ãƒ¬ãƒ¼ã‚¹å–å¾—
        # random.shuffle(tasks)
        # tasks = tasks[:10]
        safe_print(
            f"ğŸš€ æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰: {len(tasks)} ãƒ¬ãƒ¼ã‚¹åˆ†ã®ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥ã—ã¾ã™ (å…¨ä»¶å–å¾—)"
        )

        task_total = len(tasks)
        processed = 0
        results = []

        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_task = {executor.submit(process_wrapper, t): t for t in tasks}

            for future in as_completed(future_to_task):
                processed += 1
                show_progress(processed, task_total)

                try:
                    res = future.result()
                    if res:
                        results.append(res)
                except:
                    pass

        print("")

        if results:
            df = pd.DataFrame(results)

            # ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆNaNã§åŸ‹ã‚ã¦ã€é †åºã‚’çµ±ä¸€ã™ã‚‹
            df = df.reindex(columns=csv_columns)

            # è¿½è¨˜ãƒ¢ãƒ¼ãƒ‰
            df.to_csv(filename, mode="a", index=False, header=False)
            safe_print(f"  âœ… {len(df)}ãƒ¬ãƒ¼ã‚¹ ä¿å­˜ã—ã¾ã—ãŸ")
            total_races += len(df)
        else:
            safe_print(f"  âš ï¸ ãƒ‡ãƒ¼ã‚¿ãªã— (é–‹å‚¬ãªã— or ã‚¨ãƒ©ãƒ¼)")

        current += timedelta(days=1)

    safe_print("=" * 40)
    safe_print(f"ğŸ‰ ã™ã¹ã¦å®Œäº†ã—ã¾ã—ãŸï¼")
    safe_print(f"ğŸ“ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«: {filename}")
    safe_print(f"ğŸ“Š åˆè¨ˆå–å¾—æ•°: {total_races} ãƒ¬ãƒ¼ã‚¹")
    safe_print("=" * 40)
