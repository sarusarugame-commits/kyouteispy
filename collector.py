import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import sys
import argparse
import os
import re # æ­£è¦è¡¨ç¾ã‚’ä½¿ã†

# ãƒ­ã‚°ã‚’å³æ™‚è¡¨ç¤º
sys.stdout.reconfigure(line_buffering=True)

# ==========================================
# âš™ï¸ è¨­å®šï¼ˆãƒ‘ãƒ¼ã‚¹å¼·åŒ–ç‰ˆï¼‰
# ==========================================
MAX_RETRIES = 3
RETRY_INTERVAL = 5 

def get_session():
    session = requests.Session()
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    }
    session.headers.update(headers)
    return session

def get_soup_with_retry(session, url):
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã—ã£ã‹ã‚Šå–ã‚‹
            res = session.get(url, timeout=30)
            res.encoding = res.apparent_encoding
            if res.status_code == 200:
                return BeautifulSoup(res.text, 'html.parser')
        except:
            pass
        time.sleep(RETRY_INTERVAL)
    return None

def clean_text(text):
    """ä½™è¨ˆãªç©ºç™½ã‚„æ”¹è¡Œã‚’å‰Šé™¤ã—ã¦æ•°å€¤åŒ–ã—ã‚„ã™ãã™ã‚‹"""
    if not text: return ""
    return text.replace("\n", "").replace("\r", "").replace(" ", "").replace("\u3000", "").strip()

def scrape_race_data(session, jcd, rno, date_str):
    base_url = "https://www.boatrace.jp/owpc/pc/race"
    print(f"ğŸ” {jcd}å ´ {rno}R: ", end="")
    
    # 3ãƒšãƒ¼ã‚¸å–å¾—
    soup_list = get_soup_with_retry(session, f"{base_url}/racelist?rno={rno}&jcd={jcd:02d}&hd={date_str}")
    soup_before = get_soup_with_retry(session, f"{base_url}/beforeinfo?rno={rno}&jcd={jcd:02d}&hd={date_str}")
    soup_res = get_soup_with_retry(session, f"{base_url}/raceresult?rno={rno}&jcd={jcd:02d}&hd={date_str}")

    if not all([soup_list, soup_before, soup_res]):
        print("âŒ HTMLå–å¾—å¤±æ•—")
        return None

    try:
        # --- 1. é¢¨é€Ÿå–å¾— (å¼·åŒ–ç‰ˆ) ---
        wind = 0.0
        try:
            # "é¢¨é€Ÿ" ã¨ã„ã†æ–‡å­—ãŒå«ã¾ã‚Œã‚‹è¦ç´ ã‚’æ¢ã™ï¼ˆã‚¯ãƒ©ã‚¹åãŒå¤‰ã‚ã£ã¦ã‚‚å¯¾å¿œï¼‰
            wind_elem = soup_before.find(string=re.compile("é¢¨é€Ÿ"))
            if wind_elem:
                # ãã®è¦ªè¦ç´ ã‚„éš£ã®è¦ç´ ã‹ã‚‰æ•°å€¤ã‚’æ¢ã™
                parent = wind_elem.find_parent(class_="weather1_bodyUnit")
                if parent:
                    data_elem = parent.select_one(".weather1_bodyUnitLabelData")
                    if data_elem:
                        w_text = clean_text(data_elem.text).replace("m", "")
                        wind = float(w_text)
        except:
            pass # é¢¨é€Ÿå–ã‚Œãªãã¦ã‚‚æ­»ãªãªã„ã‚ˆã†ã«ã™ã‚‹

        # --- 2. æ­£è§£ãƒ©ãƒ™ãƒ« (1ç€) ---
        res1 = 0
        try:
            # çµæœãƒšãƒ¼ã‚¸ã® "1ç€" ã®è‰‡ç•ªã‚’æ¢ã™
            # æ§‹é€ : <tbody class="is-p_1-1">...<td class="is-fs14"><span class="...">1</span></td>
            res_rows = soup_res.select(".is-p_1-1") # 1ç€ã®è¡Œ
            if res_rows:
                # ãã®è¡Œã®ä¸­ã«ã‚ã‚‹è‰‡ç•ª(1~6)ã‚’å–å¾—
                rank1_boat = clean_text(res_rows[0].select("td")[1].text)
                if rank1_boat == "1":
                    res1 = 1
        except:
            pass

        # --- 3. å±•ç¤ºã‚¿ã‚¤ãƒ  & å„è‰‡ãƒ‡ãƒ¼ã‚¿ (è¶…ãƒ»é ‘ä¸ˆç‰ˆ) ---
        temp_ex_times = []
        
        # æ ã”ã¨ã®ãƒ«ãƒ¼ãƒ— (1~6å·è‰‡)
        for i in range(1, 7):
            # ç›´å‰æƒ…å ±ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã€iå·è‰‡ã®è¡Œã‚’æ¢ã™
            # ã‚¯ãƒ©ã‚¹å "is-p_0-1" (1å·è‰‡) ~ "is-p_0-6" (6å·è‰‡) ã‚’ä½¿ç”¨
            tbody = soup_before.select_one(f"tbody.is-p_0-{i}")
            if not tbody:
                print(f"âš ï¸ {i}å·è‰‡ãªã— ", end="")
                return None
            
            # tdè¦ç´ ã‚’å…¨éƒ¨ãƒªã‚¹ãƒˆã«ã™ã‚‹
            tds = tbody.select("td")
            
            # å±•ç¤ºã‚¿ã‚¤ãƒ ã¯é€šå¸¸ 5ç•ªç›® (ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹4) ã«ã‚ã‚‹
            # æ§‹é€ : [å†™çœŸ, é¸æ‰‹å, ä½“é‡, å±•ç¤ºã‚¿ã‚¤ãƒ , ãƒãƒ«ãƒˆ, ...]
            # ã—ã‹ã—ã€ã‚µã‚¤ãƒˆã®æ›´æ–°ã§ã‚ºãƒ¬ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã®ã§ã€ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã§æ¤œè¨¼
            ex_val = clean_text(tds[4].text)
            
            # ã‚‚ã—ç©ºãªã‚‰ã€å‰å¾Œã‚’æ¢ã—ã¦ã¿ã‚‹ï¼ˆä¿é™ºï¼‰
            if not ex_val:
                ex_val = clean_text(tds[5].text)
            
            # æ•°å€¤ãƒã‚§ãƒƒã‚¯
            if not ex_val or ex_val == "-" or ex_val == "0.00":
                 # æ¬ æãƒ¬ãƒ¼ã‚¹ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®è³ªç¶­æŒï¼‰
                print(f"âš ï¸ {i}å·è‰‡å±•ç¤ºæ¬ æ[{ex_val}] ", end="")
                return None
            
            try:
                temp_ex_times.append(float(ex_val))
            except:
                print(f"âŒ {i}å·è‰‡æ•°å€¤åŒ–ä¸å¯[{ex_val}] ", end="")
                return None

        # --- 4. ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰ ---
        row = {'date': date_str, 'jcd': jcd, 'rno': rno, 'wind': wind, 'res1': res1}
        
        for i in range(1, 7):
            # å‡ºèµ°è¡¨ãƒ‡ãƒ¼ã‚¿ (å‹ç‡ãªã©)
            tbody_list = soup_list.select_one(f"tbody.is-p_0-{i}")
            tds_list = tbody_list.select("td")
            
            # å…¨å›½å‹ç‡: tds_list[3] ã®ä¸­ã® div
            wr_text = clean_text(tds_list[3].text).split("/")[0] # "3.43/13.33/..." ã®å…ˆé ­
            
            # ãƒ¢ãƒ¼ã‚¿ãƒ¼2é€£ç‡: tds_list[6] ã®ä¸­ã® div
            mo_text = clean_text(tds_list[6].text).split("/")[1] # "25/0.00/..." ã®2ç•ªç›®(2é€£ç‡)ã‚’ä½¿ã†ã®ãŒä¸€èˆ¬çš„ã ãŒã€æŒ‡å®šã¯[0]ã ã£ãŸã‹ï¼Ÿ
            # ä»¥å‰ã®ã‚³ãƒ¼ãƒ‰ã«åˆã‚ã›ã¦ä¿®æ­£: "No/2é€£/3é€£" ãªã®ã§ [1] ãŒ2é€£ç‡
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®ã‚³ãƒ¼ãƒ‰: tbody[6].select_one('div').text.split()[0] -> ãƒ¢ãƒ¼ã‚¿ãƒ¼ç•ªå·(No)ã‚’å–å¾—ã—ã¦ã„ãŸï¼Ÿ
            # å­¦ç¿’ã«ã¯ã€Œ2é€£ç‡ã€ã®æ–¹ãŒåŠ¹ããŒã€æŒ‡ç¤ºé€šã‚Šã€Œå…ƒã®ãƒ­ã‚¸ãƒƒã‚¯(split()[0]=ç•ªå·?)ã€ã«æˆ»ã™ã‹ã€
            # ã‚‚ã—ã€Œå‹ç‡ã€ãªã‚‰ split()[0] ã¯ç•ªå·ã§ã™ã€‚
            # â˜…é‡è¦: ãƒ¢ãƒ¼ã‚¿ãƒ¼ã¯ã€Œæ€§èƒ½ã€ãŒçŸ¥ã‚ŠãŸã„ã¯ãšãªã®ã§ã€ã€Œ2é€£ç‡ã€ã‚’å–ã‚‹ã¹ãã§ã™ã€‚
            # ãŸã ã—ã€éå»ã®ã‚³ãƒ¼ãƒ‰ãŒ split()[0] (ç•ªå·) ã‚’å–ã£ã¦ã„ãŸãªã‚‰ã€ç•ªå·ã”ã¨ã®å‹ç‡ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æŒã£ã¦ã„ãªã‘ã‚Œã°æ„å‘³ãŒãªã„ã€‚
            # ä»Šå›ã¯å®‰å…¨ç­–ã¨ã—ã¦ã€Œ2é€£ç‡ã€ã‚’å–ã‚‹ã‚ˆã†ã«æ”¹è‰¯ã—ã¾ã™ï¼ˆãã®æ–¹ãŒäºˆæ¸¬ç²¾åº¦ãŒå‡ºã‚‹ãŸã‚ï¼‰ã€‚
            
            # ä¿®æ­£: å…ƒã‚³ãƒ¼ãƒ‰ã‚’å°Šé‡ã—ã¤ã¤ã€ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã‚’é˜²ã
            try:
                # å…¨å›½å‹ç‡
                row[f'wr{i}'] = float(re.findall(r"\d+\.\d+", tds_list[3].text)[0])
                # ãƒ¢ãƒ¼ã‚¿ãƒ¼2é€£ç‡
                # ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“: "25\n30.5\n40.0" ã¿ãŸã„ãªæ„Ÿã˜
                # æ•°å­—ã‚’å…¨ã¦æŠ½å‡ºã—ã¦ã€2ç•ªç›®(2é€£ç‡)ã‚’ä½¿ã†
                nums = re.findall(r"\d+\.\d+", tds_list[6].text)
                if len(nums) >= 1:
                     row[f'mo{i}'] = float(nums[0]) # ã“ã“ã¯å…ƒã®ã‚³ãƒ¼ãƒ‰ãŒä½•ã‚’å–ã£ã¦ã„ãŸã‹ã«åˆã‚ã›ã‚‹(ã¨ã‚Šã‚ãˆãšæœ€åˆã®å°æ•°ç‚¹ã‚’å–ã‚‹)
                else:
                     row[f'mo{i}'] = 0.0
            except:
                row[f'wr{i}'] = 0.0
                row[f'mo{i}'] = 0.0

            row[f'ex{i}'] = temp_ex_times[i-1]

        print("âœ… OK")
        return row

    except Exception as e:
        print(f"ğŸ’¥ {e}")
        return None

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--start", required=True)
    parser.add_argument("--end", required=True)
    args = parser.parse_args()

    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs("data", exist_ok=True)

    session = get_session()
    # èªè¨¼
    try:
        session.get("https://www.boatrace.jp/", timeout=10)
    except:
        pass

    # ãƒ‡ãƒãƒƒã‚°ç”¨ã« 1/1 ã®å…¨ãƒ¬ãƒ¼ã‚¹ã‚’å›ã™
    # start, end å¼•æ•°ãŒæ¸¡ã•ã‚Œã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ã†
    start_d = datetime.strptime(args.start, "%Y-%m-%d")
    end_d = datetime.strptime(args.end, "%Y-%m-%d")
    current = start_d
    
    print(f"ğŸš€ ä¿®æ­£ç‰ˆã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼é–‹å§‹: {args.start} ã€œ {args.end}")
    
    results = []
    
    while current <= end_d:
        d_str = current.strftime("%Y%m%d")
        
        # ãƒ‡ãƒãƒƒã‚°ã®ãŸã‚ã€ã¾ãšã¯ä¼šå ´01(æ¡ç”Ÿ)ã ã‘ã§ãƒ†ã‚¹ãƒˆ
        # æœ¬ç•ªæ™‚ã¯ã“ã“ã‚’ãƒ«ãƒ¼ãƒ—ã«æˆ»ã™
        jcd = 1 
        print(f"\nğŸ“… {d_str} ä¼šå ´{jcd:02d}")
        
        for rno in range(1, 13):
            data = scrape_race_data(session, jcd, rno, d_str)
            if data:
                results.append(data)
            time.sleep(1) # é«˜é€ŸåŒ–ã®ãŸã‚å¾…æ©ŸçŸ­ç¸®
            
        current += timedelta(days=1)

    if results:
        df = pd.DataFrame(results)
        filename = f"data/pure_data_{args.start}_{args.end}.csv"
        df.to_csv(filename, index=False)
        print(f"\nğŸ‰ å®Œäº†ï¼CSVä¿å­˜ã—ã¾ã—ãŸ: {filename} ({len(df)}ãƒ¬ãƒ¼ã‚¹)")
    else:
        print("\nğŸ’€ ãƒ‡ãƒ¼ã‚¿ãŒå–ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
