import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import re
import os
import unicodedata
import argparse
import random
import threading
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from requests.adapters import HTTPAdapter
from urllib3.util import Retry

# ==========================================
# âš™ï¸ è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
# ä¸¦åˆ—æ•°ã‚’20ã«å¤‰æ›´
MAX_WORKERS = 20  
MAX_RETRIES = 5
RETRY_DELAY = 3
TIMEOUT_SEC = 20

UA_LIST = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
]

print_lock = threading.Lock()

def safe_print(msg):
    with print_lock:
        print(f"[{time.strftime('%H:%M:%S')}] {msg}", flush=True)

def clean_text(text):
    if not text: return ""
    text = unicodedata.normalize('NFKC', str(text))
    return text.replace("\n", "").replace("\r", "").replace("Â¥", "").replace(",", "").strip()

def get_column_names():
    """CSVã®ã‚«ãƒ©ãƒ å®šç¾©ã‚’ä¸€ç®‡æ‰€ã§ç®¡ç†"""
    cols = ['date', 'jcd', 'rno', 'wind', 'res1', 'rank1', 'rank2', 'rank3', 
            'tansho', 'nirentan', 'sanrentan', 'sanrenpuku', 'payout']
    for i in range(1, 7):
        cols.extend([f'wr{i}', f'mo{i}', f'ex{i}', f'f{i}', f'st{i}'])
    return cols

def get_session():
    session = requests.Session()
    retries = Retry(
        total=MAX_RETRIES,
        backoff_factor=1,
        status_forcelist=[500, 502, 503, 504],
        allowed_methods=["GET"]
    )
    # ä¸¦åˆ—æ•°ã«åˆã‚ã›ã¦ãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚ºã‚‚æ‹¡å¼µ
    adapter = HTTPAdapter(pool_connections=MAX_WORKERS, pool_maxsize=MAX_WORKERS, max_retries=retries)
    session.mount("https://", adapter)
    return session

def get_soup(session, url):
    for i in range(MAX_RETRIES):
        try:
            headers = {'User-Agent': random.choice(UA_LIST)}
            res = session.get(url, headers=headers, timeout=TIMEOUT_SEC)
            res.encoding = res.apparent_encoding
            
            if res.status_code == 200:
                if "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“" in res.text or "ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹" in res.text:
                    return None, "SKIP"
                return BeautifulSoup(res.text, 'html.parser'), None
            
            if res.status_code == 404:
                return None, "ERROR"
                
            time.sleep(random.uniform(1, 2))
        except Exception:
            time.sleep(RETRY_DELAY)
            
    return None, "ERROR"

def extract_payout(soup, key_text):
    try:
        for tbl in soup.select("table"):
            if key_text in tbl.text:
                for tr in tbl.select("tr"):
                    if key_text in tr.text:
                        for td in tr.select("td"):
                            txt = clean_text(td.text)
                            if txt.isdigit() and (len(txt) >= 3 or int(txt) > 100):
                                return int(txt)
    except: pass
    return 0

def scrape_race_data(session, jcd, rno, date_str):
    base_url = "https://www.boatrace.jp/owpc/pc/race"
    
    url_res = f"{base_url}/raceresult?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    url_bef = f"{base_url}/beforeinfo?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    url_lst = f"{base_url}/racelist?rno={rno}&jcd={jcd:02d}&hd={date_str}"

    soup_res, err = get_soup(session, url_res)
    if err == "SKIP" or not soup_res: return None
    
    soup_before, _ = get_soup(session, url_bef)
    soup_list, _ = get_soup(session, url_lst)

    try:
        row = {'date': date_str, 'jcd': jcd, 'rno': rno}

        # å¤©å€™ãƒ»é¢¨
        try:
            wind_elem = soup_before.select_one(".weather1_bodyUnitLabelData") if soup_before else None
            if wind_elem:
                w_txt = clean_text(wind_elem.text)
                m = re.search(r"(\d+)", w_txt)
                row['wind'] = float(m.group(1)) if m else 0.0
            else:
                row['wind'] = 0.0
        except: row['wind'] = 0.0

        # é †ä½
        row['rank1'], row['rank2'], row['rank3'] = None, None, None
        try:
            result_rows = soup_res.select("table.is-w495 tbody tr")
            if len(result_rows) >= 1:
                r1_txt = clean_text(result_rows[0].select("td")[1].text)
                row['rank1'] = int(re.search(r"^(\d{1})", r1_txt).group(1))
            if len(result_rows) >= 2:
                r2_txt = clean_text(result_rows[1].select("td")[1].text)
                row['rank2'] = int(re.search(r"^(\d{1})", r2_txt).group(1))
            if len(result_rows) >= 3:
                r3_txt = clean_text(result_rows[2].select("td")[1].text)
                row['rank3'] = int(re.search(r"^(\d{1})", r3_txt).group(1))
        except: pass
        
        row['res1'] = 1 if row.get('rank1') == 1 else 0

        # æ‰•ã„æˆ»ã—
        row['tansho'] = extract_payout(soup_res, "å˜å‹")
        row['nirentan'] = extract_payout(soup_res, "2é€£å˜")
        row['sanrentan'] = extract_payout(soup_res, "3é€£å˜")
        row['sanrenpuku'] = extract_payout(soup_res, "3é€£è¤‡")
        row['payout'] = row['sanrentan']

        # å„è‰‡ãƒ‡ãƒ¼ã‚¿
        for i in range(1, 7):
            row[f'wr{i}'] = 0.0
            row[f'mo{i}'] = 0.0
            row[f'ex{i}'] = 0.0
            row[f'f{i}'] = 0
            row[f'st{i}'] = 0.20

            # å±•ç¤ºã‚¿ã‚¤ãƒ 
            if soup_before:
                try:
                    boat_cell = soup_before.select_one(f".is-boatColor{i}")
                    if boat_cell:
                        tr = boat_cell.find_parent("tr")
                        tds = tr.select("td")
                        if len(tds) > 4:
                            for td in tds[4:]:
                                val = clean_text(td.text)
                                if re.match(r"^\d\.\d{2}$", val):
                                    row[f'ex{i}'] = float(val)
                                    break
                except: pass

            # å‹ç‡ãƒ»Fãƒ»ST
            if soup_list:
                try:
                    list_cell = soup_list.select_one(f".is-boatColor{i}")
                    if list_cell:
                        tr = list_cell.find_parent("tr")
                        tds = tr.select("td")
                        full_row_text = " ".join([clean_text(td.text) for td in tds])
                        
                        f_match = re.search(r"F(\d+)", full_row_text)
                        if f_match: row[f'f{i}'] = int(f_match.group(1))
                        
                        st_matches = re.findall(r"(\.\d{2}|0\.\d{2})", full_row_text)
                        if st_matches:
                            for st_val in st_matches:
                                v = float(st_val)
                                if 0.0 < v < 0.5:
                                    row[f'st{i}'] = v
                                    break
                        
                        wr_matches = re.findall(r"(\d\.\d{2})", full_row_text)
                        for val in wr_matches:
                            v = float(val)
                            if 1.0 <= v <= 9.99:
                                row[f'wr{i}'] = v
                                break
                        
                        mo_matches = re.findall(r"(\d{2}\.\d{2})", full_row_text)
                        if mo_matches:
                            row[f'mo{i}'] = float(mo_matches[0])
                except: pass
        
        return row
    except: return None

def process_wrapper(args):
    session, jcd, rno, date_str = args
    # ä¸¦åˆ—æ•°ãŒå¤šã„ã®ã§ã€ã‚µãƒ¼ãƒãƒ¼ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹é›†ä¸­ã‚’é¿ã‘ã‚‹ãŸã‚ã‚ãšã‹ã«å¾…æ©Ÿ
    time.sleep(random.uniform(0.1, 0.4))
    try:
        return scrape_race_data(session, jcd, rno, date_str)
    except:
        return None

def show_progress(processed, total):
    bar_len = 30
    filled = int(bar_len * processed / total)
    bar = "=" * filled + "-" * (bar_len - filled)
    percent = 100 * processed / total
    print(f"\râ³ [{bar}] {percent:.1f}% ({processed}/{total})", end="")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    today = datetime.now().strftime("%Y-%m-%d")
    
    parser.add_argument("--start", help="é–‹å§‹æ—¥ (YYYY-MM-DD)")
    parser.add_argument("--end", help="çµ‚äº†æ—¥ (YYYY-MM-DD)")
    parser.add_argument("--year", type=int, help="æŒ‡å®šã—ãŸå¹´å…¨ä½“ã‚’åé›†")
    
    args = parser.parse_args()

    if args.year:
        start_d = datetime(args.year, 1, 1)
        end_d = datetime(args.year, 12, 31)
    else:
        s_str = args.start if args.start else yesterday
        e_str = args.end if args.end else today
        try:
            start_d = datetime.strptime(s_str, "%Y-%m-%d")
            end_d = datetime.strptime(e_str, "%Y-%m-%d")
        except ValueError:
            print("âŒ æ—¥ä»˜ã‚¨ãƒ©ãƒ¼: YYYY-MM-DD å½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            sys.exit(1)

    if start_d > end_d:
        print("âŒ ã‚¨ãƒ©ãƒ¼: é–‹å§‹æ—¥ãŒçµ‚äº†æ—¥ã‚ˆã‚Šå¾Œã«ãªã£ã¦ã„ã¾ã™ã€‚")
        sys.exit(1)

    session = get_session()
    current = start_d
    
    safe_print(f"ğŸš€ åé›†é–‹å§‹: {start_d.strftime('%Y-%m-%d')} ã€œ {end_d.strftime('%Y-%m-%d')}")
    safe_print(f"âš¡ ä¸¦åˆ—ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {MAX_WORKERS}")
    
    os.makedirs("data", exist_ok=True)
    filename = f"data/race_data_{start_d.strftime('%Y%m%d')}_{end_d.strftime('%Y%m%d')}.csv"
    
    csv_columns = get_column_names()

    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½œæˆ
    if not os.path.exists(filename):
        pd.DataFrame(columns=csv_columns).to_csv(filename, index=False)

    total_races = 0
    
    while current <= end_d:
        d_str = current.strftime("%Y%m%d")
        safe_print(f"ğŸ“… {current.strftime('%Y-%m-%d')} ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...")
        
        tasks = []
        for jcd in range(1, 25):
            for rno in range(1, 13):
                tasks.append((session, jcd, rno, d_str))
        
        task_total = len(tasks)
        processed = 0
        results = []
        
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_task = {executor.submit(process_wrapper, t): t for t in tasks}
            
            for future in as_completed(future_to_task):
                processed += 1
                show_progress(processed, task_total)
                
                try:
                    res = future.result()
                    if res: results.append(res)
                except: pass
        
        print("") 
        
        if results:
            df = pd.DataFrame(results)
            
            # ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆNaNã§åŸ‹ã‚ã¦ã€é †åºã‚’çµ±ä¸€ã™ã‚‹
            df = df.reindex(columns=csv_columns)
            
            # è¿½è¨˜ãƒ¢ãƒ¼ãƒ‰
            df.to_csv(filename, mode='a', index=False, header=False)
            safe_print(f"  âœ… {len(df)}ãƒ¬ãƒ¼ã‚¹ ä¿å­˜ã—ã¾ã—ãŸ")
            total_races += len(df)
        else:
            safe_print(f"  âš ï¸ ãƒ‡ãƒ¼ã‚¿ãªã— (é–‹å‚¬ãªã— or ã‚¨ãƒ©ãƒ¼)")
        
        current += timedelta(days=1)
    
    safe_print("="*40)
    safe_print(f"ğŸ‰ ã™ã¹ã¦å®Œäº†ã—ã¾ã—ãŸï¼")
    safe_print(f"ğŸ“ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«: {filename}")
    safe_print(f"ğŸ“Š åˆè¨ˆå–å¾—æ•°: {total_races} ãƒ¬ãƒ¼ã‚¹")
    safe_print("="*40)
