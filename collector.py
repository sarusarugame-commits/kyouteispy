import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import re
import os
import unicodedata
import argparse
import random
import threading
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from requests.adapters import HTTPAdapter
from urllib3.util import Retry

# ==========================================
# âš™ï¸ è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
MAX_WORKERS = 20  # ä¸¦åˆ—æ•°
MAX_RETRIES = 5
RETRY_DELAY = 3
TIMEOUT_SEC = 20

UA_LIST = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
]

print_lock = threading.Lock()

def safe_print(msg):
    with print_lock:
        print(f"[{time.strftime('%H:%M:%S')}] {msg}", flush=True)

def clean_text(text):
    if not text: return ""
    text = unicodedata.normalize('NFKC', str(text))
    return text.replace("\n", "").replace("\r", "").replace("Â¥", "").replace(",", "").strip()

def get_column_names():
    cols = ['date', 'jcd', 'rno', 'wind', 'res1', 'rank1', 'rank2', 'rank3', 
            'tansho', 'nirentan', 'sanrentan', 'sanrenpuku', 'payout']
    # é¸æ‰‹ID (pid) ã‚’è¿½åŠ 
    for i in range(1, 7):
        cols.extend([f'pid{i}', f'wr{i}', f'mo{i}', f'ex{i}', f'f{i}', f'st{i}'])
    return cols

def get_session():
    session = requests.Session()
    retries = Retry(
        total=MAX_RETRIES,
        backoff_factor=1,
        status_forcelist=[500, 502, 503, 504],
        allowed_methods=["GET"]
    )
    adapter = HTTPAdapter(pool_connections=MAX_WORKERS, pool_maxsize=MAX_WORKERS, max_retries=retries)
    session.mount("https://", adapter)
    return session

def get_soup(session, url):
    for i in range(MAX_RETRIES):
        try:
            headers = {'User-Agent': random.choice(UA_LIST)}
            res = session.get(url, headers=headers, timeout=TIMEOUT_SEC)
            res.encoding = res.apparent_encoding
            
            if res.status_code == 200:
                if "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“" in res.text or "ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹" in res.text:
                    return None, "SKIP"
                return BeautifulSoup(res.text, 'html.parser'), None
            
            if res.status_code == 404:
                return None, "ERROR"
                
            time.sleep(random.uniform(1, 2))
        except Exception:
            time.sleep(RETRY_DELAY)
            
    return None, "ERROR"

def extract_payout(soup, key_text):
    try:
        # é…å½“ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚ˆã‚Šå³å¯†ã«æ¤œç´¢
        for tbl in soup.select("table.is-w495"):
            if key_text in tbl.text:
                rows = tbl.select("tr")
                for tr in rows:
                    if key_text in tr.text:
                        # é‡‘é¡ã¯æœ€å¾Œã®tdã«å…¥ã£ã¦ã„ã‚‹ã“ã¨ãŒå¤šã„
                        tds = tr.select("td")
                        if not tds: continue
                        txt = clean_text(tds[-1].text)
                        if txt.isdigit():
                            return int(txt)
    except: pass
    return 0

def scrape_race_data(session, jcd, rno, date_str):
    base_url = "https://www.boatrace.jp/owpc/pc/race"
    
    url_res = f"{base_url}/raceresult?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    url_bef = f"{base_url}/beforeinfo?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    url_lst = f"{base_url}/racelist?rno={rno}&jcd={jcd:02d}&hd={date_str}"

    soup_res, err = get_soup(session, url_res)
    if err == "SKIP" or not soup_res: return None
    
    soup_before, _ = get_soup(session, url_bef)
    soup_list, _ = get_soup(session, url_lst)

    try:
        row = {'date': date_str, 'jcd': jcd, 'rno': rno}

        # å¤©å€™ãƒ»é¢¨ (beforeinfoã‹ã‚‰å–å¾—)
        row['wind'] = 0.0
        if soup_before:
            try:
                # å¤©å€™æƒ…å ±ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’æ¢ã™
                weather_div = soup_before.select_one(".weather1_body")
                if weather_div:
                    wind_elem = weather_div.select_one(".weather1_bodyUnitLabelData")
                    if wind_elem:
                        w_txt = clean_text(wind_elem.text)
                        m = re.search(r"(\d+)", w_txt)
                        row['wind'] = float(m.group(1)) if m else 0.0
            except: pass

        # é †ä½
        row['rank1'], row['rank2'], row['rank3'] = None, None, None
        try:
            result_rows = soup_res.select("table.is-w495 tbody tr")
            for idx, r_key in enumerate(['rank1', 'rank2', 'rank3']):
                if len(result_rows) > idx:
                    # ç€é †ã®æ•°å­—ã‚’å–å¾—
                    rank_td = result_rows[idx].select("td")
                    if len(rank_td) >= 2:
                        r_txt = clean_text(rank_td[1].text) # è‰‡ç•ª
                        if r_txt.isdigit():
                            row[r_key] = int(r_txt)
        except: pass
        
        row['res1'] = 1 if row.get('rank1') == 1 else 0

        # æ‰•ã„æˆ»ã—
        row['tansho'] = extract_payout(soup_res, "å˜å‹")
        row['nirentan'] = extract_payout(soup_res, "2é€£å˜")
        row['sanrentan'] = extract_payout(soup_res, "3é€£å˜")
        row['sanrenpuku'] = extract_payout(soup_res, "3é€£è¤‡")
        row['payout'] = row['sanrentan']

        # å„è‰‡ãƒ‡ãƒ¼ã‚¿å–å¾—
        for i in range(1, 7):
            # åˆæœŸåŒ–
            row[f'pid{i}'] = 0     # é¸æ‰‹ID
            row[f'wr{i}'] = 0.0    # å‹ç‡
            row[f'mo{i}'] = 0.0    # ãƒ¢ãƒ¼ã‚¿ãƒ¼
            row[f'ex{i}'] = 0.0    # å±•ç¤ºã‚¿ã‚¤ãƒ 
            row[f'f{i}'] = 0       # ãƒ•ãƒ©ã‚¤ãƒ³ã‚°
            row[f'st{i}'] = 0.20   # å¹³å‡ST

            # 1. å‡ºèµ°è¡¨(racelist)ã‹ã‚‰ ID, å‹ç‡, å¹³å‡ST, Fæ•° ã‚’å–å¾—
            if soup_list:
                try:
                    # æ ç•ªã”ã¨ã®tbodyã‚’å–å¾— (is-fs12ã‚¯ãƒ©ã‚¹ã‚’æŒã¤tbody)
                    tbodies = soup_list.select("tbody.is-fs12")
                    if len(tbodies) >= i:
                        tbody = tbodies[i-1] # æ ç•ªã«å¯¾å¿œã™ã‚‹tbody
                        
                        # --- é¸æ‰‹ID (ç™»ç•ª) ---
                        # <div class="is-fs11">4320 ... </div>
                        toban_div = tbody.select_one("div.is-fs11")
                        if toban_div:
                            toban_txt = clean_text(toban_div.text)[:4]
                            if toban_txt.isdigit():
                                row[f'pid{i}'] = int(toban_txt)

                        # --- å‹ç‡, ãƒ¢ãƒ¼ã‚¿ãƒ¼, å¹³å‡ST ---
                        # tdã‚¿ã‚°ã‚’å…¨å–å¾—ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§æŒ‡å®šã™ã‚‹ã®ãŒç¢ºå®Ÿ
                        tds = tbody.select("td")
                        
                        # å…¨å›½å‹ç‡ (é€šå¸¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹4ã‚ãŸã‚Š)
                        # HTMLæ§‹é€ : ç´šåˆ¥ | å…¨å›½å‹ç‡ | å½“åœ°å‹ç‡ ...
                        # is-lineH2 ã‚¯ãƒ©ã‚¹ã®ã‚»ãƒ«ãªã©ã‚’æ¢ã™
                        
                        # ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‹ã‚‰å‹ç‡ã£ã½ã„ã€ŒX.XXã€ã‚’æŠ½å‡ºã™ã‚‹æ­£è¦è¡¨ç¾ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
                        full_text = tbody.text
                        
                        # å‹ç‡ (1.00 - 9.99)
                        wr_match = re.search(r"(\d\.\d{2})", full_text) # æœ€åˆã«ãƒ’ãƒƒãƒˆã™ã‚‹ã®ãŒå…¨å›½å‹ç‡ã®å¯èƒ½æ€§ãŒé«˜ã„
                        if wr_match:
                            # å³å¯†ã«ã¯ td[4] ã‚’æŒ‡å®šã™ã¹ãã ãŒã€ã‚µã‚¤ãƒˆæ§‹é€ å¤‰åŒ–ã«å¼·ã„æ­£è¦è¡¨ç¾ã§è£œå®Œ
                            if len(tds) > 4:
                                wr_txt = clean_text(tds[4].text)
                                m = re.search(r"(\d\.\d{2})", wr_txt)
                                if m: row[f'wr{i}'] = float(m.group(1))

                        # ãƒ¢ãƒ¼ã‚¿ãƒ¼ (td[6] or td[7])
                        if len(tds) > 6:
                            mo_txt = clean_text(tds[6].text) # 2é€£å¯¾ç‡
                            m = re.search(r"(\d{2}\.\d{2})", mo_txt)
                            if m: row[f'mo{i}'] = float(m.group(1))
                            
                            # ã‚‚ã—ã“ã“ã«ãªã‘ã‚Œã°æ¬¡ã®ã‚»ãƒ«ã‚’ç¢ºèª
                            if row[f'mo{i}'] == 0.0 and len(tds) > 7:
                                mo_txt = clean_text(tds[7].text)
                                m = re.search(r"(\d{2}\.\d{2})", mo_txt)
                                if m: row[f'mo{i}'] = float(m.group(1))

                        # å¹³å‡ST (0.XX)
                        st_match = re.search(r"(0\.\d{2})", full_text)
                        if st_match:
                            row[f'st{i}'] = float(st_match.group(1))
                        
                        # Fæ•° (F1, F2...)
                        f_match = re.search(r"F(\d+)", full_text)
                        if f_match:
                            row[f'f{i}'] = int(f_match.group(1))
                            
                except: pass

            # 2. ç›´å‰æƒ…å ±(beforeinfo)ã‹ã‚‰ å±•ç¤ºã‚¿ã‚¤ãƒ  ã‚’å–å¾—
            if soup_before:
                try:
                    # is-boatColor1 ~ 6 ã®ã‚¯ãƒ©ã‚¹ã‚’æŒã¤tdã‚’æ¢ã™
                    boat_td = soup_before.select_one(f"td.is-boatColor{i}")
                    if boat_td:
                        # ãã®è¡Œ(tr)ã‚’å–å¾—
                        tr = boat_td.find_parent("tr")
                        tds = tr.select("td")
                        # å±•ç¤ºã‚¿ã‚¤ãƒ ã¯é€šå¸¸å¾Œã‚ã®æ–¹ã«ã‚ã‚‹ (td[4]ä»¥é™)
                        # å€¤ãŒ "6.XX" ã®ã‚ˆã†ãªå½¢å¼ã‚’æ¢ã™
                        for td in tds[4:]:
                            val = clean_text(td.text)
                            if re.match(r"^\d\.\d{2}$", val):
                                # 6.50 ~ 7.00 ãã‚‰ã„ã®å€¤ãŒå±•ç¤ºã‚¿ã‚¤ãƒ 
                                if 6.0 <= float(val) <= 7.5:
                                    row[f'ex{i}'] = float(val)
                                    break
                except: pass

        return row
    except: return None

def process_wrapper(args):
    session, jcd, rno, date_str = args
    time.sleep(random.uniform(0.1, 0.4))
    try:
        return scrape_race_data(session, jcd, rno, date_str)
    except:
        return None

def show_progress(processed, total):
    bar_len = 30
    filled = int(bar_len * processed / total)
    bar = "=" * filled + "-" * (bar_len - filled)
    percent = 100 * processed / total
    print(f"\râ³ [{bar}] {percent:.1f}% ({processed}/{total})", end="")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    today = datetime.now().strftime("%Y-%m-%d")
    
    parser.add_argument("--start", help="é–‹å§‹æ—¥ (YYYY-MM-DD)")
    parser.add_argument("--end", help="çµ‚äº†æ—¥ (YYYY-MM-DD)")
    parser.add_argument("--year", type=int, help="æŒ‡å®šã—ãŸå¹´å…¨ä½“ã‚’åé›†")
    
    args = parser.parse_args()

    if args.year:
        start_d = datetime(args.year, 1, 1)
        end_d = datetime(args.year, 12, 31)
    else:
        s_str = args.start if args.start else yesterday
        e_str = args.end if args.end else today
        try:
            start_d = datetime.strptime(s_str, "%Y-%m-%d")
            end_d = datetime.strptime(e_str, "%Y-%m-%d")
        except ValueError:
            print("âŒ æ—¥ä»˜ã‚¨ãƒ©ãƒ¼: YYYY-MM-DD å½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            sys.exit(1)

    if start_d > end_d:
        print("âŒ ã‚¨ãƒ©ãƒ¼: é–‹å§‹æ—¥ãŒçµ‚äº†æ—¥ã‚ˆã‚Šå¾Œã«ãªã£ã¦ã„ã¾ã™ã€‚")
        sys.exit(1)

    session = get_session()
    current = start_d
    
    safe_print(f"ğŸš€ åé›†é–‹å§‹: {start_d.strftime('%Y-%m-%d')} ã€œ {end_d.strftime('%Y-%m-%d')}")
    safe_print(f"âš¡ ä¸¦åˆ—ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {MAX_WORKERS}")
    
    os.makedirs("data", exist_ok=True)
    filename = f"data/race_data_{start_d.strftime('%Y%m%d')}_{end_d.strftime('%Y%m%d')}.csv"
    
    csv_columns = get_column_names()

    if not os.path.exists(filename):
        pd.DataFrame(columns=csv_columns).to_csv(filename, index=False)

    total_races = 0
    
    while current <= end_d:
        d_str = current.strftime("%Y%m%d")
        safe_print(f"ğŸ“… {current.strftime('%Y-%m-%d')} ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...")
        
        tasks = []
        for jcd in range(1, 25):
            for rno in range(1, 13):
                tasks.append((session, jcd, rno, d_str))
        
        task_total = len(tasks)
        processed = 0
        results = []
        
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_task = {executor.submit(process_wrapper, t): t for t in tasks}
            
            for future in as_completed(future_to_task):
                processed += 1
                show_progress(processed, task_total)
                
                try:
                    res = future.result()
                    if res: results.append(res)
                except: pass
        
        print("") 
        
        if results:
            df = pd.DataFrame(results)
            df = df.reindex(columns=csv_columns)
            df.to_csv(filename, mode='a', index=False, header=False)
            safe_print(f"  âœ… {len(df)}ãƒ¬ãƒ¼ã‚¹ ä¿å­˜ã—ã¾ã—ãŸ")
            total_races += len(df)
        else:
            safe_print(f"  âš ï¸ ãƒ‡ãƒ¼ã‚¿ãªã— (é–‹å‚¬ãªã— or ã‚¨ãƒ©ãƒ¼)")
        
        current += timedelta(days=1)
    
    safe_print("="*40)
    safe_print(f"ğŸ‰ ã™ã¹ã¦å®Œäº†ã—ã¾ã—ãŸï¼")
    safe_print(f"ğŸ“ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«: {filename}")
    safe_print(f"ğŸ“Š åˆè¨ˆå–å¾—æ•°: {total_races} ãƒ¬ãƒ¼ã‚¹")
    safe_print("="*40)
