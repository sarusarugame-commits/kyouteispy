import pandas as pd
from curl_cffi import requests
from bs4 import BeautifulSoup
import time
import re
import os
import unicodedata
import argparse
import random
import threading
import sys
import subprocess
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from itertools import permutations

# ==========================================
# âš™ï¸ è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
MAX_WORKERS = 15       # ä¸¦åˆ—æ•° (curl_cffiã¯é«˜é€Ÿãªã®ã§å°‘ã—æŠ‘ãˆã‚ã§OK)
TIMEOUT_SEC = 20       # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
MAX_RETRIES = 5        # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
RETRY_DELAY = 3        # ãƒªãƒˆãƒ©ã‚¤å¾…æ©Ÿç§’æ•°

print_lock = threading.Lock()

def safe_print(msg):
    with print_lock:
        timestamp = time.strftime("%H:%M:%S")
        print(f"[{timestamp}] {msg}", flush=True)

def clean_text(text):
    if not text: return ""
    text = unicodedata.normalize("NFKC", str(text))
    return text.replace("\n", "").replace("\r", "").replace("Â¥", "").replace(",", "").strip()

def get_column_names():
    """CSVã®ã‚«ãƒ©ãƒ å®šç¾©"""
    cols = [
        "date", "jcd", "rno", "wind", "res1", 
        "rank1", "rank2", "rank3", 
        "tansho", "nirentan", "sanrentan", "sanrenpuku", "payout",
    ]
    # é¸æ‰‹ãƒ‡ãƒ¼ã‚¿
    for i in range(1, 7):
        cols.extend([f"pid{i}", f"wr{i}", f"mo{i}", f"ex{i}", f"f{i}", f"st{i}"])
    
    # 3é€£å˜å…¨120é€šã‚Šã®ã‚ªãƒƒã‚ºã‚«ãƒ©ãƒ 
    for i, j, k in permutations(range(1, 7), 3):
        cols.append(f"odds_{i}-{j}-{k}")
    
    return cols

def get_session():
    # Chrome 120 ã«ãªã‚Šã™ã¾ã™
    return requests.Session(impersonate="chrome120")

def get_soup(session, url):
    for i in range(MAX_RETRIES):
        try:
            res = session.get(url, timeout=TIMEOUT_SEC)
            if res.status_code == 200:
                # æ–‡å­—åŒ–ã‘å¯¾ç­–
                res.encoding = res.charset if res.charset else 'utf-8'
                if "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“" in res.text or "ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹" in res.text:
                    return None, "SKIP"
                # â˜…é‡è¦: lxmlã‚’ä½¿ç”¨
                return BeautifulSoup(res.content, "lxml"), None
            
            if res.status_code == 404:
                return None, "ERROR"
            
            time.sleep(random.uniform(1, 2))
        except Exception:
            time.sleep(RETRY_DELAY)
    return None, "ERROR"

def extract_payout(soup, key_text):
    if not soup: return 0
    try:
        # æ‰•ã„æˆ»ã—ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
        for tbl in soup.select("table.is-w495"):
            if key_text in tbl.text:
                rows = tbl.select("tr")
                for tr in rows:
                    if key_text in tr.text:
                        tds = tr.select("td")
                        if not tds: continue
                        for td in reversed(tds):
                            txt = clean_text(td.text)
                            if txt.isdigit():
                                val = int(txt)
                                if val >= 100: return val
    except: pass
    return 0

def get_odds_map(session, jcd, rno, date_str):
    """3é€£å˜ã®å…¨ã‚ªãƒƒã‚ºã‚’å–å¾—ã—ã¦è¾æ›¸ã§è¿”ã™ (oddsPointå¯¾å¿œç‰ˆ)"""
    url = f"https://www.boatrace.jp/owpc/pc/race/odds3t?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    soup, err = get_soup(session, url)
    
    # å…¨120é€šã‚Šã®åˆæœŸåŒ–
    odds_map = {f"odds_{i}-{j}-{k}": 0.0 for i, j, k in permutations(range(1, 7), 3)}

    if not soup or err == "SKIP":
        return odds_map

    # æ­£ã—ã„ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
    target_tbody = None
    tables = soup.select("div.table1 table")
    for tbl in tables:
        # oddsPointã‚¯ãƒ©ã‚¹ã‚’æŒã¤ã‚»ãƒ«ãŒã‚ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
        if tbl.select(".oddsPoint"):
            tbody = tbl.select_one("tbody")
            if tbody:
                target_tbody = tbody
                break
    
    if not target_tbody:
        return odds_map
        
    rows = target_tbody.select("tr")
    rowspan_counters = [0] * 6
    current_2nd_boats = [0] * 6

    for tr in rows:
        tds = tr.select("td")
        col_cursor = 0
        
        for block_idx in range(6):
            if col_cursor >= len(tds): break
            current_1st = block_idx + 1 
            
            if rowspan_counters[block_idx] > 0:
                if col_cursor + 1 >= len(tds): break
                val_2nd = current_2nd_boats[block_idx]
                txt_3rd = clean_text(tds[col_cursor].text)
                txt_odds = clean_text(tds[col_cursor+1].text)
                rowspan_counters[block_idx] -= 1
                col_cursor += 2
            else:
                if col_cursor + 2 >= len(tds): break
                td_2nd = tds[col_cursor]
                txt_2nd = clean_text(td_2nd.text)
                rs = int(td_2nd.get("rowspan", 1))
                rowspan_counters[block_idx] = rs - 1
                try: val_2nd = int(txt_2nd)
                except: val_2nd = 0
                current_2nd_boats[block_idx] = val_2nd
                txt_3rd = clean_text(tds[col_cursor+1].text)
                txt_odds = clean_text(tds[col_cursor+2].text)
                col_cursor += 3

            try:
                if val_2nd > 0 and txt_3rd.isdigit():
                    odds_val = float(txt_odds) if txt_odds.replace('.','').isdigit() else 0.0
                    key = f"odds_{current_1st}-{val_2nd}-{txt_3rd}"
                    odds_map[key] = odds_val
            except:
                continue

    return odds_map

def scrape_race_data(session, jcd, rno, date_str):
    base_url = "https://www.boatrace.jp/owpc/pc/race"
    url_res = f"{base_url}/raceresult?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    url_bef = f"{base_url}/beforeinfo?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    url_lst = f"{base_url}/racelist?rno={rno}&jcd={jcd:02d}&hd={date_str}"

    soup_res, err = get_soup(session, url_res)
    if err == "SKIP" or not soup_res: return None

    soup_before, _ = get_soup(session, url_bef)
    soup_list, _ = get_soup(session, url_lst)

    try:
        row = {"date": date_str, "jcd": jcd, "rno": rno}
        
        # --- åŸºæœ¬æƒ…å ± ---
        row["wind"] = 0.0
        if soup_before:
            try:
                wind_unit = soup_before.select_one(".is-windDirection")
                if wind_unit:
                    wind_data = wind_unit.select_one(".weather1_bodyUnitLabelData")
                    if wind_data:
                        m = re.search(r"(\d+)", clean_text(wind_data.text))
                        row["wind"] = float(m.group(1)) if m else 0.0
            except: pass

        row["rank1"], row["rank2"], row["rank3"] = None, None, None
        try:
            result_rows = soup_res.select("table.is-w495 tbody tr")
            for idx, r_key in enumerate(["rank1", "rank2", "rank3"]):
                if len(result_rows) > idx:
                    rank_td = result_rows[idx].select("td")
                    if len(rank_td) >= 2:
                        r_txt = clean_text(rank_td[1].text)
                        if r_txt.isdigit(): row[r_key] = int(r_txt)
        except: pass
        row["res1"] = 1 if row.get("rank1") == 1 else 0

        # --- æ‰•ã„æˆ»ã— ---
        row["tansho"] = extract_payout(soup_res, "å˜å‹")
        row["nirentan"] = extract_payout(soup_res, "2é€£å˜")
        row["sanrentan"] = extract_payout(soup_res, "3é€£å˜")
        row["sanrenpuku"] = extract_payout(soup_res, "3é€£è¤‡")
        row["payout"] = row["sanrentan"]

        # --- ã‚ªãƒƒã‚º (å…¨120é€šã‚Š) ---
        odds_data = get_odds_map(session, jcd, rno, date_str)
        row.update(odds_data)

        # --- é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ ---
        for i in range(1, 7):
            row[f"pid{i}"] = 0; row[f"wr{i}"] = 0.0; row[f"mo{i}"] = 0.0
            row[f"ex{i}"] = 0.0; row[f"f{i}"] = 0; row[f"st{i}"] = 0.20

            if soup_list:
                try:
                    tbodies = soup_list.select("tbody.is-fs12")
                    if len(tbodies) >= i:
                        tbody = tbodies[i - 1]
                        txt_all = clean_text(tbody.text)
                        pid_match = re.search(r"([2-5]\d{3})", txt_all)
                        if pid_match: row[f"pid{i}"] = int(pid_match.group(1))

                        tds = tbody.select("td")
                        full_txt = " ".join([clean_text(td.text) for td in tds])
                        
                        m_wr = re.search(r"(\d\.\d{2})", clean_text(tds[2].text) if len(tds)>2 else "")
                        if m_wr and 1.0 <= float(m_wr.group(1)) <= 9.99:
                            row[f"wr{i}"] = float(m_wr.group(1))

                        mo_matches = re.findall(r"(\d{2}\.\d{2})", full_txt)
                        if mo_matches:
                            for m_val in mo_matches:
                                if 10.0 <= float(m_val) <= 99.9:
                                    row[f"mo{i}"] = float(m_val)
                                    break
                        st_match = re.search(r"(0\.\d{2})", full_txt)
                        if st_match: row[f"st{i}"] = float(st_match.group(1))
                        f_match = re.search(r"F(\d+)", full_txt)
                        if f_match: row[f"f{i}"] = int(f_match.group(1))
                except: pass

            if soup_before:
                try:
                    boat_td = soup_before.select_one(f"td.is-boatColor{i}")
                    if boat_td:
                        tr = boat_td.find_parent("tr")
                        if tr:
                            for td in tr.select("td")[4:]:
                                val = clean_text(td.text)
                                if re.match(r"^\d\.\d{2}$", val):
                                    if 6.0 <= float(val) <= 7.5:
                                        row[f"ex{i}"] = float(val); break
                except: pass
        return row
    except: return None

def process_wrapper(args):
    session, jcd, rno, date_str = args
    time.sleep(random.uniform(0.5, 1.5))
    try:
        res = scrape_race_data(session, jcd, rno, date_str)
        if res is None:
            safe_print(f"âš ï¸ [SKIP] {date_str} å ´:{jcd:02} R:{rno:02} -> å–å¾—å¤±æ•—")
        return res
    except Exception as e:
        safe_print(f"âŒ [ERROR] {date_str} å ´:{jcd:02} R:{rno:02} -> {e}")
        return None

def show_progress(processed, total):
    bar_len = 30
    filled = int(bar_len * processed / total)
    bar = "=" * filled + "-" * (bar_len - filled)
    percent = 100 * processed / total
    print(f"\râ³ [{bar}] {percent:.1f}% ({processed}/{total})", end="")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--start", help="é–‹å§‹æ—¥ (YYYY-MM-DD)")
    parser.add_argument("--end", help="çµ‚äº†æ—¥ (YYYY-MM-DD)")
    parser.add_argument("--year", type=int, help="æŒ‡å®šã—ãŸå¹´å…¨ä½“ã‚’åé›†")
    
    # â˜…æ–°æ©Ÿèƒ½: 1å¹´ã”ã¨ã«è‡ªå‹•å†èµ·å‹•ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰
    parser.add_argument("--year_range", type=int, nargs=2, help="é–‹å§‹å¹´ çµ‚äº†å¹´ (ä¾‹: 2020 2024)")

    args = parser.parse_args()

    # --- è‡ªå‹•ãƒªãƒ¬ãƒ¼ãƒ«ãƒ¼ãƒ—å‡¦ç† ---
    if args.year_range:
        start_y, end_y = args.year_range
        current_target_year = start_y
        
        print("="*60)
        print(f"ğŸ”„ è‡ªå‹•ãƒªãƒ¬ãƒ¼åé›†ãƒ¢ãƒ¼ãƒ‰: {start_y}å¹´ ã€œ {end_y}å¹´")
        print(f"ğŸ¯ ç¾åœ¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {current_target_year}å¹´")
        print("="*60)
        
        # å¼•æ•°ã‚’æ›¸ãæ›ãˆã¦è‡ªåˆ†è‡ªèº«ã‚’å‘¼ã³å‡ºã™æº–å‚™
        # ç¾åœ¨ã®å¹´ã®åé›†ãŒçµ‚ã‚ã£ãŸã‚‰ã€æ¬¡ã¯ (current + 1) å¹´ã‚’æŒ‡å®šã—ã¦å†èµ·å‹•ã™ã‚‹
        
        # ã¾ãšã¯æ™®é€šã«å˜å¹´ãƒ¢ãƒ¼ãƒ‰ã¨ã—ã¦å¤‰æ•°ã‚’ã‚»ãƒƒãƒˆ
        start_d = datetime(current_target_year, 1, 1)
        end_d = datetime(current_target_year, 12, 31)
        
    else:
        # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰
        yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
        if args.year:
            start_d = datetime(args.year, 1, 1)
            end_d = datetime(args.year, 12, 31)
        else:
            default_start = "2025-01-01"
            s_str = args.start if args.start else default_start
            e_str = args.end if args.end else yesterday
            try:
                start_d = datetime.strptime(s_str, "%Y-%m-%d")
                end_d = datetime.strptime(e_str, "%Y-%m-%d")
            except ValueError:
                print("âŒ æ—¥ä»˜ã‚¨ãƒ©ãƒ¼: YYYY-MM-DD å½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
                sys.exit(1)

    if start_d > end_d:
        print("âŒ ã‚¨ãƒ©ãƒ¼: é–‹å§‹æ—¥ãŒçµ‚äº†æ—¥ã‚ˆã‚Šå¾Œã«ãªã£ã¦ã„ã¾ã™ã€‚")
        sys.exit(1)

    session = get_session()
    current = start_d

    safe_print(f"ğŸš€ åé›†é–‹å§‹: {start_d.strftime('%Y-%m-%d')} ã€œ {end_d.strftime('%Y-%m-%d')}")
    safe_print(f"âš¡ ä¸¦åˆ—ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {MAX_WORKERS}")

    os.makedirs("data", exist_ok=True)
    filename = f"data/race_data_odds_{start_d.strftime('%Y%m%d')}_{end_d.strftime('%Y%m%d')}.csv"
    csv_columns = get_column_names()

    if not os.path.exists(filename):
        pd.DataFrame(columns=csv_columns).to_csv(filename, index=False)

    total_races = 0

    while current <= end_d:
        d_str = current.strftime("%Y%m%d")
        safe_print(f"ğŸ“… {current.strftime('%Y-%m-%d')} ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...")

        tasks = []
        for jcd in range(1, 25):
            for rno in range(1, 13):
                tasks.append((session, jcd, rno, d_str))

        safe_print(f"ğŸš€ {len(tasks)} ãƒ¬ãƒ¼ã‚¹åˆ†ã®ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥ã—ã¾ã™")
        
        task_total = len(tasks)
        processed = 0
        results = []

        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_task = {executor.submit(process_wrapper, t): t for t in tasks}
            for future in as_completed(future_to_task):
                processed += 1
                show_progress(processed, task_total)
                try:
                    res = future.result()
                    if res: results.append(res)
                except: pass

        print("")

        if results:
            df = pd.DataFrame(results)
            df = df.reindex(columns=csv_columns)
            df.to_csv(filename, mode="a", index=False, header=False)
            safe_print(f"  âœ… {len(df)}ãƒ¬ãƒ¼ã‚¹ ä¿å­˜ã—ã¾ã—ãŸ")
            total_races += len(df)
        else:
            safe_print(f"  âš ï¸ ãƒ‡ãƒ¼ã‚¿ãªã—")

        current += timedelta(days=1)

    safe_print("=" * 40)
    safe_print(f"ğŸ‰ {start_d.year}å¹´ã®åé›†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    safe_print(f"ğŸ“ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«: {filename}")
    safe_print("=" * 40)

    # --- è‡ªå‹•ãƒªãƒ¬ãƒ¼: æ¬¡ã®å¹´ã¸ ---
    if args.year_range:
        next_year = args.year_range[0] + 1
        end_year_limit = args.year_range[1]
        
        if next_year <= end_year_limit:
            print(f"\nğŸš€ {next_year}å¹´ã®åé›†ã‚’é–‹å§‹ã™ã‚‹ãŸã‚ã€è‡ªå‹•å†èµ·å‹•ã—ã¾ã™...\n")
            time.sleep(3) # ãƒ­ã‚°ã‚’ç¢ºèªã™ã‚‹çŒ¶äºˆ
            
            # è‡ªåˆ†è‡ªèº«ã‚’æ–°ã—ã„å¼•æ•°ã§å‘¼ã³å‡ºã™
            new_args = [sys.executable, sys.argv[0], "--year_range", str(next_year), str(end_year_limit)]
            
            # ç¾åœ¨ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã—ã€æ–°ã—ã„ãƒ—ãƒ­ã‚»ã‚¹ã«ç½®ãæ›ãˆã‚‹ (ãƒ¡ãƒ¢ãƒªè§£æ”¾)
            if sys.platform == 'win32':
                subprocess.Popen(new_args)
                sys.exit(0)
            else:
                os.execv(sys.executable, new_args)
        else:
            print("\nğŸ æŒ‡å®šã•ã‚ŒãŸå…¨æœŸé–“ã®åé›†ãŒå®Œäº†ã—ã¾ã—ãŸï¼ãŠç–²ã‚Œæ§˜ã§ã—ãŸã€‚")
