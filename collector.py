import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import sys

# ãƒ­ã‚°ã‚’å³åº§ã«å‡ºåŠ›ã™ã‚‹é–¢æ•°
def log(msg):
    print(msg, flush=True)

def get_soup(url):
    try:
        log(f"ğŸŒ ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {url}")
        res = requests.get(url, timeout=10)
        res.encoding = res.apparent_encoding
        if res.status_code == 200:
            return BeautifulSoup(res.text, 'html.parser')
        log(f"âŒ ã‚¨ãƒ©ãƒ¼: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ {res.status_code}")
    except Exception as e:
        log(f"ğŸ’¥ ä¾‹å¤–ç™ºç”Ÿ: {e}")
    return None

if __name__ == "__main__":
    log("ğŸš€ ãƒ‡ãƒãƒƒã‚°å®Ÿè¡Œé–‹å§‹ï¼ˆ1ä¼šå ´ãƒ»1ãƒ¬ãƒ¼ã‚¹é™å®šï¼‰")
    
    # ãƒ†ã‚¹ãƒˆã¨ã—ã¦ã€Œæ¡ç”Ÿ(01) 1Rã€ã ã‘ã‚’å–å¾—
    date_str = "20250101"
    jcd = 1
    rno = 1
    
    base_url = "https://www.boatrace.jp/owpc/pc/race/racelist"
    url = f"{base_url}?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    
    soup = get_soup(url)
    
    if soup:
        log("âœ… ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«æˆåŠŸã—ã¾ã—ãŸï¼")
        # è©¦ã—ã«1å·è‰‡ã®åå‰ã ã‘å‡ºã—ã¦ã¿ã‚‹
        try:
            name = soup.select_one(".name").text.strip()
            log(f"ğŸ‘¤ 1å·è‰‡ã®åå‰: {name}")
        except:
            log("âš ï¸ ãƒšãƒ¼ã‚¸æ§‹é€ ãŒé•ã†ã€ã¾ãŸã¯é¸æ‰‹åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        log("ğŸ’€ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚GitHubã®IPãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    
    log("ğŸ ãƒ‡ãƒãƒƒã‚°çµ‚äº†")
