import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime

# ==========================================
# âš™ï¸ è¨­å®š
# ==========================================
TARGET_DATE = "20250101"  # ãƒ‡ãƒãƒƒã‚°ã—ãŸã„æ—¥ä»˜ (YYYYMMDD)

def get_soup(url):
    """HTMLå–å¾—ã®å…±é€šé–¢æ•°"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, headers=headers, timeout=10)
        res.encoding = res.apparent_encoding
        return BeautifulSoup(res.text, 'html.parser')
    except Exception as e:
        print(f"âš ï¸ é€šä¿¡ã‚¨ãƒ©ãƒ¼: {url} ({e})")
        return None

def scrape_race_data(jcd, rno, date_str):
    """1ãƒ¬ãƒ¼ã‚¹åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    base_url = "https://www.boatrace.jp/owpc/pc/race"
    
    # 1. å‡ºèµ°è¡¨ï¼ˆå‹ç‡ãƒ»ãƒ¢ãƒ¼ã‚¿ãƒ¼ï¼‰
    soup_list = get_soup(f"{base_url}/racelist?rno={rno}&jcd={jcd:02d}&hd={date_str}")
    # 2. ç›´å‰æƒ…å ±ï¼ˆé¢¨é€Ÿãƒ»å±•ç¤ºï¼‰
    soup_before = get_soup(f"{base_url}/beforeinfo?rno={rno}&jcd={jcd:02d}&hd={date_str}")
    # 3. çµæœï¼ˆçš„ä¸­ç‡ã®æ­£è§£ãƒ©ãƒ™ãƒ«ç”¨ï¼‰
    soup_res = get_soup(f"{base_url}/raceresult?rno={rno}&jcd={jcd:02d}&hd={date_str}")

    if not all([soup_list, soup_before, soup_res]): return None

    try:
        # é¢¨é€Ÿ (wind)
        w_text = soup_before.select_one('.weather1_bodyUnitLabelData').text.replace('m','').strip()
        wind = float(w_text) if w_text else 0.0

        # æ­£è§£ãƒ©ãƒ™ãƒ«: 1å·è‰‡ãŒ1ç€ãªã‚‰1ã€ãã‚Œä»¥å¤–ãªã‚‰0
        res1_text = soup_res.select_one('.is-p_0-1 .is-p_1-1') 
        res1 = 1 if (res1_text and res1_text.text.strip() == "1") else 0

        row = {'date': date_str, 'jcd': jcd, 'rno': rno, 'wind': wind, 'res1': res1}

        # 1ã€œ6å·è‰‡ã®åŸºæœ¬ãƒ‡ãƒ¼ã‚¿
        for i in range(1, 7):
            # å‹ç‡ (wr) ã¨ ãƒ¢ãƒ¼ã‚¿ãƒ¼ (mo)
            tbody = soup_list.select(f'tbody.is-p_0-{i}')[0].select('td')
            row[f'wr{i}'] = float(tbody[3].select_one('div').text.split()[0])
            row[f'mo{i}'] = float(tbody[6].select_one('div').text.split()[0])
            
            # å±•ç¤ºã‚¿ã‚¤ãƒ  (ex) - æ¬ ææ™‚ã¯å¹³å‡å€¤6.70
            ex_val = soup_before.select(f'tbody.is-p_0-{i}')[0].select('td')[4].text.strip()
            row[f'ex{i}'] = float(ex_val) if ex_val else 6.70

        return row
    except Exception as e:
        # ãƒ¬ãƒ¼ã‚¹ãŒé–‹å‚¬ã•ã‚Œã¦ã„ãªã„ã€ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ä¸è¶³
        return None

def main():
    print(f"ğŸš€ {TARGET_DATE} ã®ãƒ‡ãƒãƒƒã‚°åé›†ã‚’é–‹å§‹ã—ã¾ã™...")
    results = []
    
    # å…¨24ä¼šå ´ Ã— 12ãƒ¬ãƒ¼ã‚¹ã‚’èµ°æŸ»
    for jcd in range(1, 25):
        print(f"ğŸŸï¸ ä¼šå ´ã‚³ãƒ¼ãƒ‰ {jcd:02d} ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­...")
        for rno in range(1, 13):
            data = scrape_race_data(jcd, rno, TARGET_DATE)
            if data:
                results.append(data)
                print(f"  âœ… {rno}R å–å¾—æˆåŠŸ")
            time.sleep(0.1) # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›

    if results:
        df = pd.DataFrame(results)
        filename = f"debug_data_{TARGET_DATE}.csv"
        df.to_csv(filename, index=False)
        print(f"\nâœ¨ åé›†å®Œäº†ï¼ {len(df)} ãƒ¬ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
    else:
        print("\nâŒ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == "__main__":
    main()
