import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import sys
import argparse
import os

# ãƒ­ã‚°å³æ™‚è¡¨ç¤º
sys.stdout.reconfigure(line_buffering=True)

# ==========================================
# âš™ï¸ è¨­å®šï¼šHTMLç¾ç‰©ä¿å­˜ãƒ¢ãƒ¼ãƒ‰
# ==========================================
MAX_RETRIES = 3
RETRY_INTERVAL = 5 

def get_session():
    session = requests.Session()
    # ã‚ãˆã¦ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ˜ãƒƒãƒ€ãƒ¼ã«æˆ»ã—ã¦ã¿ã‚‹ï¼ˆéåº¦ãªå½è£…ãŒé€†åŠ¹æœãªå ´åˆãŒã‚ã‚‹ãŸã‚ï¼‰
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    }
    session.headers.update(headers)
    return session

def scrape_race_data(session, jcd, rno, date_str):
    url_list = f"https://www.boatrace.jp/owpc/pc/race/racelist?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    
    print(f"ğŸ” {jcd}å ´ {rno}R: ã‚¢ã‚¯ã‚»ã‚¹ä¸­...", end="")
    
    try:
        res = session.get(url_list, timeout=20)
        res.encoding = res.apparent_encoding
        
        # HTMLã®ä¸­èº«ã‚’ãƒã‚§ãƒƒã‚¯
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—
        title = soup.title.text.strip() if soup.title else "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"
        
        # âŒ ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã¹ããƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
        target_table = soup.select_one('table.is-w495')
        
        if target_table:
            print(f" âœ… æˆåŠŸï¼(ã‚¿ã‚¤ãƒˆãƒ«: {title})")
            # ã“ã“ã§æœ¬æ¥ã®ãƒ‡ãƒ¼ã‚¿å–å¾—å‡¦ç†...ï¼ˆä»Šå›ã¯çœç•¥ï¼‰
            return {'status': 'ok'}
        else:
            print(f" âŒ ãƒ‡ãƒ¼ã‚¿ãªã— (ã‚¿ã‚¤ãƒˆãƒ«: {title})")
            
            # ğŸ”¥ å¤±æ•—ã—ãŸHTMLã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ï¼ˆã“ã‚ŒãŒè¨¼æ‹ ã«ãªã‚‹ï¼‰
            filename = f"error_html_{rno}.html"
            with open(filename, "w", encoding="utf-8") as f:
                f.write(res.text)
            print(f" ğŸ’¾ HTMLã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
            
            return None

    except Exception as e:
        print(f" ğŸ’¥ ã‚¨ãƒ©ãƒ¼: {e}")
        return None

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--start", required=True)
    parser.add_argument("--end", required=True)
    args = parser.parse_args()

    session = get_session()
    
    # èªè¨¼
    try:
        session.get("https://www.boatrace.jp/", timeout=10)
    except:
        pass

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    scrape_race_data(session, 1, 1, "20250101")
