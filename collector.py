import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import re
import os
import unicodedata
import sys
import argparse

# ==========================================
# âš™ï¸ è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
DEFAULT_TARGET_DATE = "20250101" 
MAX_RACES = 5 

def log(msg):
    """ãƒ­ã‚°ã‚’å³æ™‚å‡ºåŠ›ã™ã‚‹ãŸã‚ã®é–¢æ•°ï¼ˆflush=Trueå¿…é ˆï¼‰"""
    print(f"[{time.strftime('%H:%M:%S')}] {msg}", flush=True)

def clean_text(text):
    if not text: return ""
    text = unicodedata.normalize('NFKC', str(text))
    return text.replace("\n", "").replace("\r", "").replace(" ", "").replace("Â¥", "").replace(",", "").strip()

def get_soup(url, description="ãƒšãƒ¼ã‚¸"):
    """HTMLå–å¾—ï¼ˆè©³ç´°ãƒ­ã‚°ä»˜ãï¼‰"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    for i in range(1, 4): # 3å›ãƒªãƒˆãƒ©ã‚¤
        try:
            # log(f"  -> {description} ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­ (è©¦è¡Œ{i}/3)...")
            res = requests.get(url, headers=headers, timeout=10)
            res.encoding = res.apparent_encoding
            
            if res.status_code == 200:
                if "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“" in res.text:
                    log(f"     âš ï¸ {description}: ãƒ‡ãƒ¼ã‚¿ãªã—")
                    return None
                return BeautifulSoup(res.text, 'html.parser')
            else:
                log(f"     âš ï¸ {description}: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ç•°å¸¸ {res.status_code}")
                time.sleep(1)
        except Exception as e:
            log(f"     âŒ {description}: ã‚¨ãƒ©ãƒ¼ {e} (ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™)")
            time.sleep(1)
            
    log(f"     ğŸ’€ {description}: å–å¾—å¤±æ•—ï¼ˆã‚®ãƒ–ã‚¢ãƒƒãƒ—ï¼‰")
    return None

def scrape_race(jcd, rno, date_str):
    """1ãƒ¬ãƒ¼ã‚¹åˆ†ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    log(f"ğŸ ã€{jcd}å ´ {rno}Rã€‘ ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
    base_url = "https://www.boatrace.jp/owpc/pc/race"
    
    # URLç”Ÿæˆ
    url_before = f"{base_url}/beforeinfo?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    url_res = f"{base_url}/raceresult?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    url_list = f"{base_url}/racelist?rno={rno}&jcd={jcd:02d}&hd={date_str}"
    
    # ãƒšãƒ¼ã‚¸å–å¾—ï¼ˆä¸€ã¤ãšã¤ç¢ºèªï¼‰
    soup_before = get_soup(url_before, "ç›´å‰æƒ…å ±")
    if not soup_before: return None

    soup_res = get_soup(url_res, "ãƒ¬ãƒ¼ã‚¹çµæœ")
    if not soup_res: return None

    soup_list = get_soup(url_list, "ç•ªçµ„è¡¨")
    if not soup_list: return None

    try:
        log(f"  -> ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºãƒ»è§£æä¸­...")
        row = {'date': date_str, 'jcd': jcd, 'rno': rno}

        # --- â‘  é¢¨é€Ÿ ---
        try:
            wind_elem = soup_before.select_one(".weather1_bodyUnitLabelData")
            row['wind'] = float(clean_text(wind_elem.text).replace("m", "")) if wind_elem else 0.0
        except: row['wind'] = 0.0

        # --- â‘¡ ç€é † (rank1, rank2, rank3) ---
        row['rank1'], row['rank2'], row['rank3'] = None, None, None
        try:
            rank_rows = soup_res.select("table.is-w495 tbody tr")
            for r in rank_rows:
                tds = r.select("td")
                if len(tds) > 1:
                    rank_idx = clean_text(tds[0].text)
                    boat_num = clean_text(tds[1].text)
                    if rank_idx.isdigit() and int(rank_idx) <= 3:
                        row[f'rank{rank_idx}'] = int(boat_num)
        except: pass
        
        row['res1'] = 1 if row.get('rank1') == 1 else 0

        # --- â‘¢ 3é€£å˜é…å½“ (payout) ---
        row['payout'] = 0
        try:
            payout_th = soup_res.find(lambda tag: tag.name == "th" and "3é€£å˜" in tag.text)
            if payout_th:
                payout_td = payout_th.find_next_sibling("td").find_next_sibling("td")
                if payout_td:
                    val = clean_text(payout_td.text)
                    if val.isdigit():
                        row['payout'] = int(val)
        except: pass

        # --- â‘£ å„è‰‡ãƒ‡ãƒ¼ã‚¿ ---
        for i in range(1, 7):
            try:
                # å±•ç¤ºã‚¿ã‚¤ãƒ 
                boat_cell = soup_before.select_one(f".is-boatColor{i}")
                if boat_cell:
                    tds = boat_cell.find_parent("tbody").select("td")
                    ex_val = clean_text(tds[4].text)
                    row[f'ex{i}'] = float(ex_val) if ex_val and ex_val != "." else 0.0
                else: row[f'ex{i}'] = 0.0

                # è©³ç´°ãƒ‡ãƒ¼ã‚¿
                list_tbody = soup_list.select_one(f".is-boatColor{i}").find_parent("tbody")
                tds = list_tbody.select("td")
                
                wr_match = re.search(r"(\d\.\d{2})", clean_text(tds[3].text))
                row[f'wr{i}'] = float(wr_match.group(1)) if wr_match else 0.0
                
                f_match = re.search(r"F(\d+)", clean_text(tds[2].text))
                row[f'f{i}'] = int(f_match.group(1)) if f_match else 0
                
                st_match = re.search(r"ST(\d\.\d{2})", list_tbody.text.replace("\n", ""))
                row[f'st{i}'] = float(st_match.group(1)) if st_match else 0.17
                
                mo_text = clean_text(tds[5].text)
                mo_match = re.search(r"(\d{1,3}\.\d)", mo_text)
                if not mo_match:
                    mo_text = clean_text(tds[6].text)
                    mo_match = re.search(r"(\d{1,3}\.\d)", mo_text)
                row[f'mo{i}'] = float(mo_match.group(1)) if mo_match else 0.0
                
            except:
                row[f'wr{i}'], row[f'f{i}'], row[f'st{i}'], row[f'mo{i}'] = 0.0, 0, 0.20, 0.0

        log(f"  âœ… å–å¾—æˆåŠŸ (1ç€:{row.get('rank1')} / é…å½“:Â¥{row.get('payout')})")
        return row

    except Exception as e:
        log(f"  âŒ ãƒ‡ãƒ¼ã‚¿è§£æã‚¨ãƒ©ãƒ¼: {e}")
        return None

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--start", default=DEFAULT_TARGET_DATE)
    parser.add_argument("--end", default=None)
    args = parser.parse_args()

    target_date = args.start.replace("-", "")
    log(f"ğŸš€ DEBUG START: {target_date} (Max: {MAX_RACES} races)")
    log("==================================================")
    
    collected_data = []
    
    # 24å ´Ã—12Rã‚’å·¡å›
    for jcd in range(1, 25):
        if len(collected_data) >= MAX_RACES: break
        
        for rno in range(1, 13):
            if len(collected_data) >= MAX_RACES: break
            
            data = scrape_race(jcd, rno, target_date)
            if data:
                collected_data.append(data)
                time.sleep(1) # è² è·è»½æ¸›
            
    # CSVä¿å­˜
    if collected_data:
        log("==================================================")
        os.makedirs("data", exist_ok=True)
        df = pd.DataFrame(collected_data)
        
        cols = ['date', 'jcd', 'rno', 'wind', 'res1', 'rank1', 'rank2', 'rank3', 'payout']
        for i in range(1, 7):
            cols.extend([f'wr{i}', f'mo{i}', f'ex{i}', f'f{i}', f'st{i}'])
        
        use_cols = [c for c in cols if c in df.columns]
        df = df[use_cols]

        output_path = "data/debug_result.csv"
        df.to_csv(output_path, index=False)
        log(f"ğŸ‰ å®Œäº†ï¼ {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
    else:
        log("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒ1ä»¶ã‚‚å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        sys.exit(1)
